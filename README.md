# Quick Draw AI Sketch Generator

A lightweight diffusion-based AI model that generates hand-drawn sketches inspired by Googleâ€™s Quick Draw dataset.

This project demonstrates how a U-Netâ€“based diffusion model can generate simple grayscale sketches efficiently, even under limited GPU memory constraints.

---

## ğŸ¨ Example Output

![Generated Sketch](generated_sketches.png)

*Example sketch generated by the trained diffusion model.*

---

## ğŸš€ What You Get

* AI model that generates sketch-style drawings (e.g., cats, dogs, cars)
* Diffusion model with U-Net, residual blocks, and self-attention
* Runs inside a Docker container
* Compatible with Windows 11
* No training required to generate sketches (pretrained inference supported)

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ inference.py          # Script to generate sketches (inference)
â”œâ”€â”€ train.py              # Training script (optional)
â”œâ”€â”€ generated_sketches.png# Sample generated output
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project documentation
```

---

## ğŸ§  Model Overview

* Image size: **32Ã—32 grayscale**
* Architecture: **U-Net with residual blocks and self-attention**
* Training objective: Predict noise using **MSE loss**
* Optimized using mixed-precision training and gradient checkpointing

---

## â–¶ï¸ Quick Start (Inference)

```bash
pip install -r requirements.txt
python inference.py
```

Generated sketches will be saved locally.

---

## ğŸ› ï¸ Training (Optional)

```bash
python train.py
```

Training is optional and intended for experimentation or further fine-tuning.

---

## ğŸ“Œ Notes

* Designed to run on limited GPU resources (e.g., NVIDIA T4, 16GB VRAM)
* Focuses on architectural clarity and efficiency rather than high-resolution output

---

## ğŸ“„ License

This project is for educational and research purposes.
